{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test script to replace color in an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : \n",
    "* <https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/>\n",
    "* <https://stackoverflow.com/questions/46903885/map-rgb-semantic-maps-to-one-hot-encodings-and-vice-versa-in-tensorflow>\n",
    "* <https://datascience.stackexchange.com/questions/48338/why-are-my-predictions-broken-when-performing-image-segmentation-with-tensorflow>\n",
    "* <https://stackoverflow.com/questions/60761711/how-to-convert-multi-class-one-hot-tensor-to-rgb-in-tensorflow>\n",
    "* <https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/>\n",
    "* <https://discuss.pytorch.org/t/converting-class-tensor-from-segmentation-to-image/57165>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mIgnoring pip: markers 'python_version < \"3\"' don't match your environment\u001b[0m\r\n",
      "Requirement already satisfied: torchvision in /localscratch/vincelf.9007740.0/pyenv36/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: numpy in /localscratch/vincelf.9007740.0/pyenv36/lib/python3.6/site-packages (from torchvision)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /localscratch/vincelf.9007740.0/pyenv36/lib/python3.6/site-packages (from torchvision)\r\n",
      "Requirement already satisfied: torch==1.5.0 in /localscratch/vincelf.9007740.0/pyenv36/lib/python3.6/site-packages (from torchvision)\r\n",
      "Requirement already satisfied: future in /localscratch/vincelf.9007740.0/pyenv36/lib/python3.6/site-packages (from torch==1.5.0->torchvision)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import io\n",
    "import math\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ground truth image and check the shape and the uniq colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=873x484 at 0x2B88323F43C8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_gt='/home/vincelf/downloads/freiburg_forest_annotated/test/GT_color'\n",
    "gt_color='b378-61_mask.png'\n",
    "gt_color_f = os.path.join(home_gt, gt_color)\n",
    "#gt_color_img = io.imread(gt_color_f)\n",
    "#gt_color_img.shape\n",
    "#(481, 868, 3)\n",
    "gt_color_img = Image.open(gt_color_f)\n",
    "gt_color_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484, 873, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_color_img_rgb = gt_color_img.convert('RGB')\n",
    "gt_data = np.array(gt_color_img_rgb)   # \"data\" is a height x width x 4 numpy array\n",
    "gt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 120, 255), (0, 255, 0), (102, 102, 51), (170, 170, 170)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_color_ref = set( tuple(v) for m2d in gt_data for v in m2d )\n",
    "gt_color_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_color_ref.add((0,0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load predicted image and check the shape and the uniq colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=873x484 at 0x2B883299D6A0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_pred='/home/vincelf/upload'\n",
    "color_pred='b378-61_mask_pred_new_color.jpg'\n",
    "color_pred_f = os.path.join(home_pred, color_pred)\n",
    "color_pred_img_io_imread = io.imread(color_pred_f)\n",
    "color_pred_img = Image.open(color_pred_f)\n",
    "color_pred_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484, 873, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_pred_img_rgb = color_pred_img.convert('RGB')\n",
    "pred_data = np.array(color_pred_img_rgb)   # \"data\" is a height x width x 4 numpy array\n",
    "pred_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the uniq colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0),\n",
       " (0, 0, 2),\n",
       " (0, 1, 0),\n",
       " (0, 119, 255),\n",
       " (0, 120, 253),\n",
       " (0, 120, 255),\n",
       " (0, 121, 254),\n",
       " (0, 121, 255),\n",
       " (0, 254, 0),\n",
       " (0, 255, 0),\n",
       " (0, 255, 1),\n",
       " (1, 0, 0),\n",
       " (1, 1, 1),\n",
       " (1, 119, 253),\n",
       " (1, 119, 255),\n",
       " (1, 255, 0),\n",
       " (1, 255, 1),\n",
       " (2, 120, 254),\n",
       " (2, 120, 255),\n",
       " (100, 102, 52),\n",
       " (100, 103, 50),\n",
       " (101, 101, 49),\n",
       " (101, 103, 53),\n",
       " (102, 102, 50),\n",
       " (102, 102, 52),\n",
       " (103, 101, 50),\n",
       " (103, 101, 52),\n",
       " (103, 103, 51),\n",
       " (103, 103, 53),\n",
       " (104, 102, 51),\n",
       " (104, 102, 53),\n",
       " (169, 169, 169),\n",
       " (169, 171, 168),\n",
       " (169, 171, 170),\n",
       " (170, 170, 168),\n",
       " (170, 170, 170),\n",
       " (170, 170, 172),\n",
       " (171, 169, 170),\n",
       " (171, 169, 172),\n",
       " (171, 170, 168),\n",
       " (171, 171, 171),\n",
       " (171, 171, 173),\n",
       " (172, 170, 171)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_set = set( tuple(v) for m2d in pred_data for v in m2d )\n",
    "color_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(102, 102, 51)]\n",
      "(101, 101, 49) 101.0 0.0 101.0 102.0 (102, 102, 51)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(0, 255, 1) 0.0 0.0 255.0 255.0 (0, 255, 0)\n",
      "[(170, 170, 170)]\n",
      "(171, 169, 170) 171.0 0.0 169.0 170.0 (170, 170, 170)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(1, 0, 0) 1.0 0.0 0.0 255.0 (0, 0, 0)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(1, 119, 253) 1.0 0.0 119.0 255.0 (0, 120, 255)\n",
      "[(102, 102, 51)]\n",
      "(104, 102, 51) 104.0 0.0 102.0 102.0 (102, 102, 51)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(0, 120, 255) 0.0 0.0 120.0 255.0 (0, 120, 255)\n",
      "[(170, 170, 170)]\n",
      "(169, 169, 169) 169.0 0.0 169.0 170.0 (170, 170, 170)\n",
      "[(170, 170, 170)]\n",
      "(170, 170, 170) 170.0 0.0 170.0 170.0 (170, 170, 170)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(0, 120, 253) 0.0 0.0 120.0 255.0 (0, 120, 255)\n",
      "[(102, 102, 51)]\n",
      "(100, 103, 50) 100.0 0.0 103.0 102.0 (102, 102, 51)\n",
      "[(170, 170, 170)]\n",
      "(170, 170, 168) 170.0 0.0 170.0 170.0 (170, 170, 170)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(2, 120, 255) 2.0 0.0 120.0 255.0 (0, 120, 255)\n",
      "[(170, 170, 170)]\n",
      "(169, 171, 170) 169.0 0.0 171.0 170.0 (170, 170, 170)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(2, 120, 254) 2.0 0.0 120.0 255.0 (0, 120, 255)\n",
      "[(170, 170, 170)]\n",
      "(172, 170, 171) 172.0 0.0 170.0 170.0 (170, 170, 170)\n",
      "[(170, 170, 170)]\n",
      "(171, 170, 168) 171.0 0.0 170.0 170.0 (170, 170, 170)\n",
      "[(170, 170, 170)]\n",
      "(169, 171, 168) 169.0 0.0 171.0 170.0 (170, 170, 170)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(1, 255, 1) 1.0 0.0 255.0 255.0 (0, 255, 0)\n",
      "[(102, 102, 51)]\n",
      "(102, 102, 50) 102.0 0.0 102.0 102.0 (102, 102, 51)\n",
      "[(170, 170, 170)]\n",
      "(170, 170, 172) 170.0 0.0 170.0 170.0 (170, 170, 170)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(0, 0, 2) 0.0 0.0 0.0 255.0 (0, 0, 0)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(1, 255, 0) 1.0 0.0 255.0 255.0 (0, 255, 0)\n",
      "[(102, 102, 51)]\n",
      "(103, 103, 51) 103.0 0.0 103.0 102.0 (102, 102, 51)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(0, 119, 255) 0.0 0.0 119.0 255.0 (0, 120, 255)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(0, 0, 0) 0.0 0.0 0.0 255.0 (0, 0, 0)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(0, 254, 0) 0.0 0.0 254.0 255.0 (0, 255, 0)\n",
      "[(102, 102, 51)]\n",
      "(103, 103, 53) 103.0 0.0 103.0 102.0 (102, 102, 51)\n",
      "[(102, 102, 51)]\n",
      "(103, 101, 52) 103.0 0.0 101.0 102.0 (102, 102, 51)\n",
      "[(170, 170, 170)]\n",
      "(171, 171, 171) 171.0 0.0 171.0 170.0 (170, 170, 170)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(1, 1, 1) 1.0 0.0 1.0 255.0 (0, 0, 0)\n",
      "[(102, 102, 51)]\n",
      "(104, 102, 53) 104.0 0.0 102.0 102.0 (102, 102, 51)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(0, 121, 254) 0.0 0.0 121.0 255.0 (0, 120, 255)\n",
      "[(102, 102, 51)]\n",
      "(103, 101, 50) 103.0 0.0 101.0 102.0 (102, 102, 51)\n",
      "[(102, 102, 51)]\n",
      "(100, 102, 52) 100.0 0.0 102.0 102.0 (102, 102, 51)\n",
      "[(170, 170, 170)]\n",
      "(171, 171, 173) 171.0 0.0 171.0 170.0 (170, 170, 170)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(0, 121, 255) 0.0 0.0 121.0 255.0 (0, 120, 255)\n",
      "[(102, 102, 51)]\n",
      "(102, 102, 52) 102.0 0.0 102.0 102.0 (102, 102, 51)\n",
      "[(170, 170, 170)]\n",
      "(171, 169, 172) 171.0 0.0 169.0 170.0 (170, 170, 170)\n",
      "[(102, 102, 51)]\n",
      "(101, 103, 53) 101.0 0.0 103.0 102.0 (102, 102, 51)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(0, 1, 0) 0.0 0.0 1.0 255.0 (0, 0, 0)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(0, 255, 0) 0.0 0.0 255.0 255.0 (0, 255, 0)\n",
      "[(0, 120, 255), (0, 0, 0), (0, 255, 0)]\n",
      "(1, 119, 255) 1.0 0.0 119.0 255.0 (0, 120, 255)\n",
      "[[(101, 101, 49), (102, 102, 51)], [(0, 255, 1), (0, 255, 0)], [(171, 169, 170), (170, 170, 170)], [(1, 0, 0), (0, 0, 0)], [(1, 119, 253), (0, 120, 255)], [(104, 102, 51), (102, 102, 51)], [(0, 120, 255), (0, 120, 255)], [(169, 169, 169), (170, 170, 170)], [(170, 170, 170), (170, 170, 170)], [(0, 120, 253), (0, 120, 255)], [(100, 103, 50), (102, 102, 51)], [(170, 170, 168), (170, 170, 170)], [(2, 120, 255), (0, 120, 255)], [(169, 171, 170), (170, 170, 170)], [(2, 120, 254), (0, 120, 255)], [(172, 170, 171), (170, 170, 170)], [(171, 170, 168), (170, 170, 170)], [(169, 171, 168), (170, 170, 170)], [(1, 255, 1), (0, 255, 0)], [(102, 102, 50), (102, 102, 51)], [(170, 170, 172), (170, 170, 170)], [(0, 0, 2), (0, 0, 0)], [(1, 255, 0), (0, 255, 0)], [(103, 103, 51), (102, 102, 51)], [(0, 119, 255), (0, 120, 255)], [(0, 0, 0), (0, 0, 0)], [(0, 254, 0), (0, 255, 0)], [(103, 103, 53), (102, 102, 51)], [(103, 101, 52), (102, 102, 51)], [(171, 171, 171), (170, 170, 170)], [(1, 1, 1), (0, 0, 0)], [(104, 102, 53), (102, 102, 51)], [(0, 121, 254), (0, 120, 255)], [(103, 101, 50), (102, 102, 51)], [(100, 102, 52), (102, 102, 51)], [(171, 171, 173), (170, 170, 170)], [(0, 121, 255), (0, 120, 255)], [(102, 102, 52), (102, 102, 51)], [(171, 169, 172), (170, 170, 170)], [(101, 103, 53), (102, 102, 51)], [(0, 1, 0), (0, 0, 0)], [(0, 255, 0), (0, 255, 0)], [(1, 119, 255), (0, 120, 255)]]\n"
     ]
    }
   ],
   "source": [
    "ref_color_set = gt_color_ref\n",
    "color_set_map = []\n",
    "for color in color_set:\n",
    "    these_ref_color = []\n",
    "    c1 = color[0] + 0.00001\n",
    "    for ref_color in ref_color_set:\n",
    "        ref_c1 = ref_color[0] + 0.00001\n",
    "        rel_c1 = round(math.sqrt(abs(c1 - ref_c1)**2))\n",
    "        if( rel_c1 <= 2 ):\n",
    "            these_ref_color.append(ref_color)\n",
    "    print(these_ref_color)\n",
    "    # loop in the sub array if more than one color\n",
    "    this_ref_color = ()\n",
    "    c2 = color[1] + 0.00001\n",
    "    for ref_color in these_ref_color:\n",
    "        ref_c2 = ref_color[1] + 0.00001\n",
    "        rel_c2 = round(math.sqrt(abs(c2 - ref_c2)**2))\n",
    "        if( rel_c2 <= 2 ):\n",
    "            this_ref_color = ref_color\n",
    "    print(color, round(c1), round(ref_c1), round(c2), round(ref_c2), this_ref_color)\n",
    "    color_set_map.append([color, this_ref_color])\n",
    "print(color_set_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " array([[255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        ...,\n",
       "        [120, 120, 120, ..., 255, 255, 255],\n",
       "        [120, 120, 120, ..., 255, 255, 255],\n",
       "        [120, 120, 120, ..., 255, 255, 255]], dtype=uint8),\n",
       " array([[  1,   1,   1, ...,   1,   1,   1],\n",
       "        [  1,   1,   1, ...,   1,   1,   1],\n",
       "        [  1,   1,   1, ...,   1,   1,   1],\n",
       "        ...,\n",
       "        [255, 255, 255, ...,   1,   1,   1],\n",
       "        [255, 255, 255, ...,   1,   1,   1],\n",
       "        [255, 255, 255, ...,   1,   1,   1]], dtype=uint8))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red, green, blue = pred_data.T # Temporarily unpack the bands for readability\n",
    "red, green, blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace some color by it's reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace pred_color with reference\n",
    "# source: https://stackoverflow.com/questions/3752476/python-pil-replace-a-single-rgba-color\n",
    "# some_color = (red == 101) & (green == 101) & (blue == 49)\n",
    "# pred_data[some_color.T] = (102, 102, 51) # Transpose back needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in color_set_map:\n",
    "    # Replace pred_color with reference\n",
    "    some_color = (red == c[0][0]) & (green == c[0][1]) & (blue == c[0][2])\n",
    "    pred_data[some_color.T] = (c[1][0], c[1][1], c[1][2]) # Transpose back needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484, 873, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [  0, 120, 255],\n",
       "        [  0, 120, 255],\n",
       "        [  0, 120, 255]],\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [  0, 120, 255],\n",
       "        [  0, 120, 255],\n",
       "        [  0, 120, 255]],\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [  0, 120, 255],\n",
       "        [  0, 120, 255],\n",
       "        [  0, 120, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0]],\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0]],\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0), (0, 120, 255), (0, 255, 0), (102, 102, 51), (170, 170, 170)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_set = set( tuple(v) for m2d in pred_data for v in m2d )\n",
    "color_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reconvert into an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=873x484 at 0x2B883299D9B0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im2 = Image.fromarray(pred_data)\n",
    "im2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=873x484 at 0x2B883299D278>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_pred_img_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert color to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 120, 255],\n",
       "       [  0,   0,   0],\n",
       "       [170, 170, 170],\n",
       "       [102, 102,  51],\n",
       "       [  0, 255,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#palette = np.array([(0, 120, 255), (0, 255, 0), (102, 102, 51), (170, 170, 170)], np.uint8)\n",
    "palette = np.array(list(gt_color_ref), np.uint8)\n",
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        ...,\n",
       "        [  0, 120, 255],\n",
       "        [  0, 120, 255],\n",
       "        [  0, 120, 255]],\n",
       "\n",
       "       [[  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        ...,\n",
       "        [  0, 120, 255],\n",
       "        [  0, 120, 255],\n",
       "        [  0, 120, 255]],\n",
       "\n",
       "       [[  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        ...,\n",
       "        [  0, 120, 255],\n",
       "        [  0, 120, 255],\n",
       "        [  0, 120, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        ...,\n",
       "        [  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        [  0, 255,   1]],\n",
       "\n",
       "       [[  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        ...,\n",
       "        [  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        [  0, 255,   1]],\n",
       "\n",
       "       [[  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        ...,\n",
       "        [  0, 255,   1],\n",
       "        [  0, 255,   1],\n",
       "        [  0, 255,   1]]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_pred_img_io_imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(484, 873), dtype=bool, numpy=\n",
       " array([[False, False, False, ...,  True,  True,  True],\n",
       "        [False, False, False, ...,  True,  True,  True],\n",
       "        [False, False, False, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]])>,\n",
       " <tf.Tensor: shape=(484, 873), dtype=bool, numpy=\n",
       " array([[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]])>,\n",
       " <tf.Tensor: shape=(484, 873), dtype=bool, numpy=\n",
       " array([[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]])>,\n",
       " <tf.Tensor: shape=(484, 873), dtype=bool, numpy=\n",
       " array([[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]])>,\n",
       " <tf.Tensor: shape=(484, 873), dtype=bool, numpy=\n",
       " array([[ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]])>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_map = []\n",
    "for colour in palette:\n",
    "  class_map = tf.reduce_all(tf.equal(pred_data, colour), axis=-1)\n",
    "  semantic_map.append(class_map)\n",
    "semantic_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(484, 873, 5), dtype=bool, numpy=\n",
       "array([[[False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        ...,\n",
       "        [ True, False, False, False, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [ True, False, False, False, False]],\n",
       "\n",
       "       [[False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        ...,\n",
       "        [ True, False, False, False, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [ True, False, False, False, False]],\n",
       "\n",
       "       [[False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        ...,\n",
       "        [ True, False, False, False, False],\n",
       "        [ True, False, False, False, False],\n",
       "        [ True, False, False, False, False]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        ...,\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False,  True]],\n",
       "\n",
       "       [[False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        ...,\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False,  True]],\n",
       "\n",
       "       [[False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        ...,\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False,  True]]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_map = tf.stack(semantic_map, axis=-1)\n",
    "semantic_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(484, 873, 5), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE cast to tf.float32 because most neural networks operate in float32.\n",
    "semantic_map = tf.cast(semantic_map, tf.float32)\n",
    "semantic_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([484, 873, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         ...,\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         ...,\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         ...,\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 1.]]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.expand_dims(semantic_map,0)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 484, 873, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(y_true, y_pred):\n",
    "  intersection = np.logical_and(y_true, y_pred)\n",
    "  union = np.logical_or(y_true, y_pred)\n",
    "  iou_score = np.sum(intersection) / np.sum(union)\n",
    "  return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 484, 873, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_semantic_map = []\n",
    "for colour in palette:\n",
    "  class_map = tf.reduce_all(tf.equal(gt_data, colour), axis=-1)\n",
    "  gt_semantic_map.append(class_map)\n",
    "gt_semantic_map\n",
    "gt_semantic_map = tf.stack(gt_semantic_map, axis=-1)\n",
    "gt_semantic_map\n",
    "# NOTE cast to tf.float32 because most neural networks operate in float32.\n",
    "gt_semantic_map = tf.cast(gt_semantic_map, tf.float32)\n",
    "gt_semantic_map\n",
    "y_true = np.expand_dims(gt_semantic_map,0)\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2021201232471002"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palette = tf.constant(palette, dtype=tf.uint8)\n",
    "#palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_indexes = tf.argmax(semantic_map, axis=-1)\n",
    "#class_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new = np.expand_dims(class_indexes,0)\n",
    "#new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new2 = np.stack((new,)*4,-1)\n",
    "#new2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE this operation flattens class_indexes\n",
    "#class_indexes = tf.reshape(class_indexes, [-1])\n",
    "#class_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color_image = tf.gather(palette, class_indexes)\n",
    "#color_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Scalar tensor has no `len()`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-c05179c4db6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/localscratch/vincelf.9007740.0/pyenv36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;34m\"\"\"Returns the length of the first dimension in the Tensor.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Scalar tensor has no `len()`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Scalar tensor has no `len()`"
     ]
    }
   ],
   "source": [
    "x = torch.LongTensor(palette)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = torch.LongTensor(y_pred)\n",
    "arg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converted_tensor = torch.nn.functional.embedding(arg, x)\n",
    "#converted_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'converted_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-8071cf107f39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconverted_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'converted_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "converted_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_pil = transforms.ToPILImage()\n",
    "#img = to_pil(converted_tensor[0:-1])\n",
    "#img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_np(y_true, y_pred, metric_name, metric_type='standard', drop_last = True, mean_per_class=False, verbose=False):\n",
    "    \"\"\" \n",
    "    Compute mean metrics of two segmentation masks, via numpy.\n",
    "    \n",
    "    IoU(A,B) = |A & B| / (| A U B|)\n",
    "    Dice(A,B) = 2*|A & B| / (|A| + |B|)\n",
    "    \n",
    "    Args:\n",
    "        y_true: true masks, one-hot encoded.\n",
    "        y_pred: predicted masks, either softmax outputs, or one-hot encoded.\n",
    "        metric_name: metric to be computed, either 'iou' or 'dice'.\n",
    "        metric_type: one of 'standard' (default), 'soft', 'naive'.\n",
    "          In the standard version, y_pred is one-hot encoded and the mean\n",
    "          is taken only over classes that are present (in y_true or y_pred).\n",
    "          The 'soft' version of the metrics are computed without one-hot \n",
    "          encoding y_pred.\n",
    "          The 'naive' version return mean metrics where absent classes contribute\n",
    "          to the class mean as 1.0 (instead of being dropped from the mean).\n",
    "        drop_last = True: boolean flag to drop last class (usually reserved\n",
    "          for background class in semantic segmentation)\n",
    "        mean_per_class = False: return mean along batch axis for each class.\n",
    "        verbose = False: print intermediate results such as intersection, union\n",
    "          (as number of pixels).\n",
    "    Returns:\n",
    "        IoU/Dice of y_true and y_pred, as a float, unless mean_per_class == True\n",
    "          in which case it returns the per-class metric, averaged over the batch.\n",
    "    \n",
    "    Inputs are B*W*H*N tensors, with\n",
    "        B = batch size,\n",
    "        W = width,\n",
    "        H = height,\n",
    "        N = number of classes\n",
    "    \"\"\"\n",
    "    \n",
    "    assert y_true.shape == y_pred.shape, 'Input masks should be same shape, instead are {}, {}'.format(y_true.shape, y_pred.shape)\n",
    "    assert len(y_pred.shape) == 4, 'Inputs should be B*W*H*N tensors, instead have shape {}'.format(y_pred.shape)\n",
    "    \n",
    "    flag_soft = (metric_type == 'soft')\n",
    "    flag_naive_mean = (metric_type == 'naive')\n",
    "    \n",
    "    num_classes = y_pred.shape[-1]\n",
    "    # if only 1 class, there is no background class and it should never be dropped\n",
    "    drop_last = drop_last and num_classes>1\n",
    "    \n",
    "    if not flag_soft:\n",
    "        if num_classes>1:\n",
    "            # get one-hot encoded masks from y_pred (true masks should already be in correct format, do it anyway)\n",
    "            y_pred = np.array([ np.argmax(y_pred, axis=-1)==i for i in range(num_classes) ]).transpose(1,2,3,0)\n",
    "            y_true = np.array([ np.argmax(y_true, axis=-1)==i for i in range(num_classes) ]).transpose(1,2,3,0)\n",
    "        else:\n",
    "            y_pred = (y_pred > 0).astype(int)\n",
    "            y_true = (y_true > 0).astype(int)\n",
    "    \n",
    "    # intersection and union shapes are batch_size * n_classes (values = area in pixels)\n",
    "    axes = (1,2) # W,H axes of each image\n",
    "    intersection = np.sum(np.abs(y_pred * y_true), axis=axes) # or, np.logical_and(y_pred, y_true) for one-hot\n",
    "    mask_sum = np.sum(np.abs(y_true), axis=axes) + np.sum(np.abs(y_pred), axis=axes)\n",
    "    union = mask_sum  - intersection # or, np.logical_or(y_pred, y_true) for one-hot\n",
    "    \n",
    "    if verbose:\n",
    "        print('intersection (pred*true), intersection (pred&true), union (pred+true-inters), union (pred|true)')\n",
    "        print(intersection, np.sum(np.logical_and(y_pred, y_true), axis=axes), union, np.sum(np.logical_or(y_pred, y_true), axis=axes))\n",
    "    \n",
    "    smooth = .001\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    dice = 2*(intersection + smooth)/(mask_sum + smooth)\n",
    "    \n",
    "    metric = {'iou': iou, 'dice': dice}[metric_name]\n",
    "    \n",
    "    # define mask to be 0 when no pixels are present in either y_true or y_pred, 1 otherwise\n",
    "    mask =  np.not_equal(union, 0).astype(int)\n",
    "    # mask = 1 - np.equal(union, 0).astype(int) # True = 1\n",
    "    \n",
    "    if drop_last:\n",
    "        metric = metric[:,:-1]\n",
    "        mask = mask[:,:-1]\n",
    "    \n",
    "    # return mean metrics: remaining axes are (batch, classes)\n",
    "    # if mean_per_class, average over batch axis only\n",
    "    # if flag_naive_mean, average over absent classes too\n",
    "    if mean_per_class:\n",
    "        if flag_naive_mean:\n",
    "            return np.mean(metric, axis=0)\n",
    "        else:\n",
    "            # mean only over non-absent classes in batch (still return 1 if class absent for whole batch)\n",
    "            return (np.sum(metric * mask, axis=0) + smooth)/(np.sum(mask, axis=0) + smooth)\n",
    "    else:\n",
    "        if flag_naive_mean:\n",
    "            return np.mean(metric)\n",
    "        else:\n",
    "            # mean only over non-absent classes\n",
    "            class_count = np.sum(mask, axis=0)\n",
    "            return np.mean(np.sum(metric * mask, axis=0)[class_count!=0]/(class_count[class_count!=0]))\n",
    "        \n",
    "def mean_iou_np(y_true, y_pred, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute mean Intersection over Union of two segmentation masks, via numpy.\n",
    "    \n",
    "    Calls metrics_np(y_true, y_pred, metric_name='iou'), see there for allowed kwargs.\n",
    "    \"\"\"\n",
    "    return metrics_np(y_true, y_pred, metric_name='iou', **kwargs)\n",
    "\n",
    "def mean_dice_np(y_true, y_pred, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute mean Dice coefficient of two segmentation masks, via numpy.\n",
    "    \n",
    "    Calls metrics_np(y_true, y_pred, metric_name='dice'), see there for allowed kwargs.\n",
    "    \"\"\"\n",
    "    return metrics_np(y_true, y_pred, metric_name='dice', **kwargs)\n",
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection (pred*true), intersection (pred&true), union (pred+true-inters), union (pred|true)\n",
      "[[30744     0 39387  8658 63297]] [[30744     0 39387  8658 63297]] [[ 85099   4608  56894 268023 288354]] [[ 85099   4608  56894 268023 288354]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.36191144, 0.00099922, 0.69259482, 0.03326993, 0.22029115])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_np(y_true, y_pred, metric_name='iou', metric_type='standard', drop_last = False, mean_per_class=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection (pred*true), intersection (pred&true), union (pred+true-inters), union (pred|true)\n",
      "[[30744     0 39387  8658 63297]] [[30744     0 39387  8658 63297]] [[ 85099   4608  56894 268023 288354]] [[ 85099   4608  56894 268023 288354]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.53125612, 0.00099943, 0.81834932, 0.0635212 , 0.36063834])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_np(y_true, y_pred, metric_name='dice', metric_type='standard', drop_last = False, mean_per_class=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=422532.0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magic_number = tf.reduce_sum(semantic_map)\n",
    "magic_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 1267596 values, but the requested shape has 1252524 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/localscratch/vincelf.9007740.0/pyenv36/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8074\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Reshape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8075\u001b[0;31m         tld.op_callbacks, tensor, shape)\n\u001b[0m\u001b[1;32m   8076\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-4604202c9cec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclass_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolor_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_indexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcolor_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m481\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m868\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcolor_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/localscratch/vincelf.9007740.0/pyenv36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m   \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/localscratch/vincelf.9007740.0/pyenv36/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8078\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8079\u001b[0m         return reshape_eager_fallback(\n\u001b[0;32m-> 8080\u001b[0;31m             tensor, shape, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   8081\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8082\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/localscratch/vincelf.9007740.0/pyenv36/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape_eager_fallback\u001b[0;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[1;32m   8105\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tshape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8106\u001b[0m   _result = _execute.execute(b\"Reshape\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 8107\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   8108\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8109\u001b[0m     _execute.record_gradient(\n",
      "\u001b[0;32m/localscratch/vincelf.9007740.0/pyenv36/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 1267596 values, but the requested shape has 1252524 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "palette = tf.constant(palette, dtype=tf.uint8)\n",
    "class_indexes = tf.argmax(semantic_map, axis=-1)\n",
    "# NOTE this operation flattens class_indexes\n",
    "class_indexes = tf.reshape(class_indexes, [-1])\n",
    "color_image = tf.gather(palette, class_indexes)\n",
    "color_image = tf.reshape(color_image, [481, 868, 3])\n",
    "color_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 481, 868])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#color_image_2 = tf.transpose(color_image, perm=[2, 0, 1]).numpy()\n",
    "#color_image_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=868x481 at 0x2B5D3B884710>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.image.encode_png(color_image)\n",
    "to_pil = transforms.ToPILImage()\n",
    "img3 = to_pil(color_image.numpy()).convert('RGB')\n",
    "img3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=868x481 at 0x2B5D34DACE80>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_pred_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_pred_img == img3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(481, 868, 3), dtype=bool, numpy=\n",
       "array([[[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]]])>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = tf.math.equal(pred_data, color_image)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.boolean_mask(diff, np.array([[[False]]]))\n",
    "# tf.where([False], diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the image\n",
    "\n",
    "Reference : <https://www.pyimagesearch.com/2017/06/19/image-difference-with-opencv-and-python/>\n",
    "\n",
    "A SSIM of 1 is a perfect match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mIgnoring pip: markers 'python_version < \"3\"' don't match your environment\u001b[0m\n",
      "Collecting opencv-python\n",
      "Requirement already satisfied: numpy>=1.11.3 in /localscratch/vincelf.9007740.0/pyenv36/lib/python3.6/site-packages (from opencv-python)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-3.4.4.19\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --no-index opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import compare_ssim\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the two input images\n",
    "#imageA = cv2.imread(im2)\n",
    "#imageB = cv2.imread(im3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the images to grayscale\n",
    "grayA = cv2.cvtColor(pred_data, cv2.COLOR_BGR2GRAY)\n",
    "grayB = cv2.cvtColor(color_image.numpy(), cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM: 1.0\n"
     ]
    }
   ],
   "source": [
    "(score, diff) = compare_ssim(grayA, grayB, full=True)\n",
    "diff = (diff * 255).astype(\"uint8\")\n",
    "print(\"SSIM: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
